import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import datetime
import re
from pathlib import Path

# ==========================================
# 1. Streamlit åˆæœŸè¨­å®š (å¿…ãšæœ€åˆã«å®Ÿè¡Œ)
# ==========================================
st.set_page_config(layout="wide", page_title="ä¸å‹•ç”£ã‚¨ãƒªã‚¢åˆ†æãƒ„ãƒ¼ãƒ«")

# ãƒ™ãƒ¼ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
BASE_DIR = Path(__file__).resolve().parent

# ==========================================
# 2. Backend Logic (æ—§ back.py + ä¿®æ­£ç‰ˆ)
# ==========================================

# --- å®šæ•° ---
DEFAULT_CITY_LIST = ["å·è¶Šå¸‚"]
TOWN_CHOME_HYOSYO_FULL = [2, 3, 4]

NAME_NORMALIZATION_MAP = {
    'äººå£ç·æ•°': 'ç·äººå£',
    'ä¸€èˆ¬ä¸–å¸¯æ•°ï¼ˆä¸–å¸¯äººå“¡ï¼–äººä»¥ä¸Šå«ã‚€ï¼‰': 'ä¸€èˆ¬ä¸–å¸¯æ•°',
    'ä¸–å¸¯äººå“¡ï¼‘äºº': 'ä¸–å¸¯äººå“¡1äºº',
    'ä¸–å¸¯äººå“¡ï¼’äºº': 'ä¸–å¸¯äººå“¡2äºº',
    'ä¸–å¸¯äººå“¡ï¼”äºº': 'ä¸–å¸¯äººå“¡4äºº',
    'ä¸€èˆ¬ä¸–å¸¯ç·æ•°': 'ä¸€èˆ¬ä¸–å¸¯ç·æ•°_å®¶æ—',
    'ï¼‘ï¼˜æ­³æœªæº€ä¸–å¸¯å“¡ã®ã„ã‚‹ä¸€èˆ¬ä¸–å¸¯ç·æ•°': 'å­è‚²ã¦ä¸–å¸¯æ•°(ä»®)',
    'ï¼–ï¼•æ­³ä»¥ä¸Šä¸–å¸¯å“¡ã®ã„ã‚‹ä¸€èˆ¬ä¸–å¸¯ç·æ•°': 'é«˜é½¢è€…ä¸–å¸¯æ•°',
    'ç·æ•°': 'ä¸–å¸¯ç·æ•°_çµŒæ¸ˆ',
    'ä½å®…ã«ä½ã‚€ä¸€èˆ¬ä¸–å¸¯': 'ä½å®…ä¸–å¸¯'
}

def data_path(filename: str) -> str:
    return str(BASE_DIR / filename)

# --- CSVèª­ã¿è¾¼ã¿ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ---
def read_csv_safe(file_path, skiprows=None):
    """ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ç”¨ï¼šçµ±è¨ˆCSVèª­ã¿è¾¼ã¿ï¼ˆæ–‡å­—ã‚³ãƒ¼ãƒ‰è‡ªå‹•åˆ¤å®šï¼‰"""
    encodings = ['utf-8', 'cp932', 'utf-8-sig']
    for enc in encodings:
        try:
            return pd.read_csv(
                file_path,
                encoding=enc,
                skiprows=skiprows,
                dtype={"KEY_CODE": "string"}
            )
        except Exception:
            continue
    return pd.DataFrame()

def normalize_key_code_series(s: pd.Series) -> pd.Series:
    s = s.astype("string")
    s = s.str.replace(r"\D", "", regex=True)
    return s

def filter_key_code_len(df: pd.DataFrame, allowed_len: int = 9) -> pd.DataFrame:
    if df.empty or "KEY_CODE" not in df.columns:
        return df
    df = df.copy()
    df["KEY_CODE"] = normalize_key_code_series(df["KEY_CODE"])
    return df[df["KEY_CODE"].str.len() == allowed_len].copy()

# --- ã‚³ãƒ¼ãƒ‰å¯¾å¿œè¡¨èª­ã¿è¾¼ã¿ ---
def load_column_mapping():
    df = read_csv_safe(data_path('code_mapping.csv'))
    if df.empty or 'CODE' not in df.columns or 'NAME' not in df.columns:
        return {}
    return dict(zip(df['CODE'], df['NAME']))

# --- å¸‚åŒºç”ºæ‘ä¸€è¦§å–å¾— ---
def get_available_cities(file_name='population.csv'):
    df = read_csv_safe(data_path(file_name))
    if df.empty:
        return []
    df = filter_key_code_len(df, allowed_len=9)
    if 'CITYNAME' in df.columns:
        return sorted(df['CITYNAME'].dropna().unique().tolist())
    return []

# --- çµ±è¨ˆãƒ‡ãƒ¼ã‚¿é›†è¨ˆãƒ­ã‚¸ãƒƒã‚¯ ---
def load_and_aggregate(file_name, mapping_dict, target_cities):
    df = read_csv_safe(data_path(file_name))
    if df.empty or 'CITYNAME' not in df.columns:
        return pd.DataFrame()

    # 9æ¡ã®ã¿ï¼ˆ11æ¡=ä¸ç›®ã‚’ç„¡è¦–ï¼‰
    df = filter_key_code_len(df, allowed_len=9)

    df = df[df['CITYNAME'].isin(target_cities)].copy()

    if 'HYOSYO' in df.columns:
        df = df[df['HYOSYO'].isin(TOWN_CHOME_HYOSYO_FULL)].copy()

    # åˆ—åå¤‰æ›
    df = df.rename(columns=mapping_dict)
    df = df.rename(columns=NAME_NORMALIZATION_MAP)

    if 'NAME' in df.columns:
        df['AREA_NAME'] = df['NAME']
    else:
        df['AREA_NAME'] = df['KEY_CODE']

    # ä¸è¦åˆ—å‰Šé™¤
    cols_to_drop = ['KEY_CODE', 'HYOSYO', 'CITYNAME', 'NAME', 'HTKSYORI', 'HTKSAKI', 'GASSAN']
    df = df.drop(columns=[c for c in cols_to_drop if c in df.columns], errors='ignore')

    # æ•°å€¤åŒ–
    cols_to_convert = [c for c in df.columns if c != 'AREA_NAME']
    for col in cols_to_convert:
        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)

    df_agg = df.groupby('AREA_NAME')[cols_to_convert].sum().reset_index()
    return df_agg

# --- å–å¼•ãƒ‡ãƒ¼ã‚¿ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚° ---
def filter_price_types(price_df: pd.DataFrame) -> pd.DataFrame:
    if price_df.empty or "ç¨®é¡" not in price_df.columns:
        return price_df

    out = price_df.copy()
    s = out["ç¨®é¡"].astype(str)

    # é™¤å¤–ãƒ¯ãƒ¼ãƒ‰
    exclude_keywords = ["è¾²åœ°", "æ—åœ°", "å±±æ—", "æ± æ²¼", "åŸé‡"]
    mask_exclude = s.str.contains("|".join(exclude_keywords), na=False)
    out = out[~mask_exclude].copy()

    # å„ªå…ˆãƒ¯ãƒ¼ãƒ‰ï¼ˆãŸã ã—å…¨æ»…ã™ã‚‹ãªã‚‰æˆ»ã™å‡¦ç†ã®ãŸã‚keep_keywordså®šç¾©ï¼‰
    keep_keywords = ["å®…åœ°", "åœŸåœ°", "ä¸­å¤ãƒãƒ³ã‚·ãƒ§ãƒ³", "ãƒãƒ³ã‚·ãƒ§ãƒ³"]
    mask_keep = out["ç¨®é¡"].astype(str).str.contains("|".join(keep_keywords), na=False)
    kept = out[mask_keep].copy()

    return kept if not kept.empty else out

# --- ä½æ°‘ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æ¨å®š ---
def add_resident_profile(merged_df: pd.DataFrame) -> pd.DataFrame:
    df = merged_df.copy()

    if "ç·äººå£" not in df.columns:
        return df

    denom = df["ç·äººå£"].replace(0, 1)
    cols = list(df.columns)

    def find_cols(patterns):
        hit = []
        for c in cols:
            s = str(c)
            if any(re.search(p, s) for p in patterns):
                hit.append(c)
        return hit

    child_cols = find_cols([r"0[-ã€œ]?14", r"14æ­³ä»¥ä¸‹", r"å¹´å°‘", r"å¹´å°‘äººå£", r"15æ­³æœªæº€"])
    work_cols  = find_cols([r"15[-ã€œ]?64", r"ç”Ÿç”£å¹´é½¢", r"ç”Ÿç”£å¹´é½¢äººå£", r"15æ­³ä»¥ä¸Š64æ­³ä»¥ä¸‹"])
    elder_cols = find_cols([r"65æ­³ä»¥ä¸Š", r"è€å¹´", r"è€å¹´äººå£", r"é«˜é½¢", r"é«˜é½¢è€…"])

    df["å­ã©ã‚‚äººå£_æ¨å®š"] = df[child_cols].sum(axis=1) if child_cols else 0
    df["ç¾å½¹äººå£_æ¨å®š"]   = df[work_cols].sum(axis=1) if work_cols else 0
    df["é«˜é½¢äººå£_æ¨å®š"]   = df[elder_cols].sum(axis=1) if elder_cols else 0

    df["å­ã©ã‚‚ç‡"] = df["å­ã©ã‚‚äººå£_æ¨å®š"] / denom
    df["ç¾å½¹ç‡"]   = df["ç¾å½¹äººå£_æ¨å®š"] / denom
    df["é«˜é½¢è€…ç‡"] = df["é«˜é½¢äººå£_æ¨å®š"] / denom

    return df

# --- ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•° ---
def get_city_data(target_city_names=DEFAULT_CITY_LIST, uploaded_price_df=None):
    if isinstance(target_city_names, str):
        target_city_names = [target_city_names]

    mapping = load_column_mapping()

    # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df_pop   = load_and_aggregate('population.csv',        mapping, target_city_names)
    df_age   = load_and_aggregate('age.csv',               mapping, target_city_names)
    df_size  = load_and_aggregate('household_size.csv',    mapping, target_city_names)
    df_family= load_and_aggregate('family_type.csv',       mapping, target_city_names)
    df_eco   = load_and_aggregate('economic_status.csv',   mapping, target_city_names)
    df_owner = load_and_aggregate('housing_ownership.csv', mapping, target_city_names)
    df_struct= load_and_aggregate('housing_structure.csv', mapping, target_city_names)

    # æ´¾ç”ŸæŒ‡æ¨™è¨ˆç®—
    if not df_size.empty and 'ä¸€èˆ¬ä¸–å¸¯æ•°' in df_size.columns:
        hh = df_size['ä¸€èˆ¬ä¸–å¸¯æ•°'].replace(0, 1)
        p1 = df_size.get('ä¸–å¸¯äººå“¡1äºº', 0)
        p2 = df_size.get('ä¸–å¸¯äººå“¡2äºº', 0)
        p4 = df_size.get('ä¸–å¸¯äººå“¡4äºº', 0)
        df_size['å˜èº«ãƒ»å°‘äººæ•°ä¸–å¸¯å‰²åˆ'] = (p1 + p2) / hh
        df_size['ãƒ•ã‚¡ãƒŸãƒªãƒ¼ä¸–å¸¯å‰²åˆ'] = p4 / hh

    if not df_family.empty and 'ä¸€èˆ¬ä¸–å¸¯ç·æ•°_å®¶æ—' in df_family.columns:
        fam_hh = df_family['ä¸€èˆ¬ä¸–å¸¯ç·æ•°_å®¶æ—'].replace(0, 1)
        if 'é«˜é½¢è€…ä¸–å¸¯æ•°' in df_family.columns:
            df_family['é«˜é½¢åŒ–ç‡'] = df_family['é«˜é½¢è€…ä¸–å¸¯æ•°'] / fam_hh

    if not df_owner.empty and 'ä½å®…ä¸–å¸¯' in df_owner.columns:
        house_hh = df_owner['ä½å®…ä¸–å¸¯'].replace(0, 1)
        if 'æŒã¡å®¶' in df_owner.columns:
            df_owner['æŒã¡å®¶ç‡'] = df_owner['æŒã¡å®¶'] / house_hh
        if 'æ°‘å–¶å€Ÿå®¶' in df_owner.columns:
            df_owner['å€Ÿå®¶ç‡'] = df_owner['æ°‘å–¶å€Ÿå®¶'] / house_hh

    if not df_struct.empty and 'ä¸»ä¸–å¸¯æ•°' in df_struct.columns:
        main_hh = df_struct['ä¸»ä¸–å¸¯æ•°'].replace(0, 1)
        if 'ä¸€æˆ¸å»º' in df_struct.columns:
            df_struct['ä¸€æˆ¸å»ºç‡'] = df_struct['ä¸€æˆ¸å»º'] / main_hh
        if 'å…±åŒä½å®…' in df_struct.columns:
            df_struct['å…±åŒä½å®…ç‡'] = df_struct['å…±åŒä½å®…'] / main_hh

    # ãƒ‡ãƒ¼ã‚¿çµåˆ
    dfs = [d for d in [df_pop, df_age, df_size, df_family, df_eco, df_owner, df_struct] if not d.empty]
    
    if not dfs:
        # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã§ã‚‚ã€åœ°ä¾¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°å‡¦ç†ã‚’ç¶šè¡Œã™ã‚‹ãŸã‚ã«ç©ºDataFrameä½œæˆ
        merged_df = pd.DataFrame(columns=['AREA_NAME'])
    else:
        merged_df = dfs[0]
        for d in dfs[1:]:
            merged_df = pd.merge(merged_df, d, on='AREA_NAME', how='outer')

    if not merged_df.empty:
        merged_df = merged_df.set_index('AREA_NAME').fillna(0)
        merged_df.index.name = "AREA_NAME"

    if 'ç·äººå£' in merged_df.columns and 'ä¸–å¸¯ç·æ•°' in merged_df.columns:
        merged_df['1ä¸–å¸¯å½“ãŸã‚Šäººå“¡'] = merged_df['ç·äººå£'] / merged_df['ä¸–å¸¯ç·æ•°'].replace(0, 1)

    # ä½æ°‘ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«è¿½åŠ 
    merged_df = add_resident_profile(merged_df)

    # ---- åœ°ä¾¡ï¼ˆå–å¼•ï¼‰ãƒ‡ãƒ¼ã‚¿çµ±åˆ ----
    price_df = uploaded_price_df.copy() if uploaded_price_df is not None else pd.DataFrame()

    if not price_df.empty:
        # å¸‚åŒºç”ºæ‘ã§çµã‚‹
        if 'å¸‚åŒºç”ºæ‘å' in price_df.columns:
            price_df = price_df[price_df['å¸‚åŒºç”ºæ‘å'].isin(target_city_names)].copy()

        # è¾²åœ°/æ—åœ°ç­‰ã‚’é™¤å¤–
        price_df = filter_price_types(price_df)

        if 'åœ°åŒºå' in price_df.columns:
            # --- â˜… ä¿®æ­£ç®‡æ‰€ã“ã“ã‹ã‚‰ï¼šå˜ä¾¡ã®è‡ªå‹•è¨ˆç®— ---
            
            # é¢ç©ã®æ•°å€¤åŒ–ï¼ˆã€Œ2000ã¡ä»¥ä¸Šã€ãªã©ã®æ–‡å­—åˆ—å¯¾å¿œï¼‰
            def _clean_area_local(x):
                try:
                    s = str(x).replace(",", "").replace("ã¡ä»¥ä¸Š", "").replace("m^2", "").replace("m2", "")
                    nums = re.findall(r"[\d.]+", s)
                    return float(nums[0]) if nums else None
                except:
                    return None
            
            area_col = 'é¢ç©ï¼ˆã¡ï¼‰' if 'é¢ç©ï¼ˆã¡ï¼‰' in price_df.columns else None
            price_col = 'å–å¼•ä¾¡æ ¼ï¼ˆç·é¡ï¼‰' if 'å–å¼•ä¾¡æ ¼ï¼ˆç·é¡ï¼‰' in price_df.columns else None

            # è¨ˆç®—ç”¨ã®ä¸€æ™‚åˆ—ä½œæˆ
            if area_col:
                price_df['area_calc'] = price_df[area_col].apply(_clean_area_local)
            else:
                price_df['area_calc'] = None
            
            if price_col:
                price_df['total_price'] = pd.to_numeric(price_df[price_col], errors='coerce')
            else:
                price_df['total_price'] = None

            # å˜ä¾¡è¨ˆç®—ï¼ˆç·é¡ / é¢ç©ï¼‰
            price_df['calc_unit_price'] = price_df['total_price'] / price_df['area_calc'].replace(0, np.nan)

            # å…ƒã€…ã®ã€Œå–å¼•ä¾¡æ ¼ï¼ˆã¡å˜ä¾¡ï¼‰ã€ãŒã‚ã‚Œã°èª­ã¿è¾¼ã‚€
            if 'å–å¼•ä¾¡æ ¼ï¼ˆã¡å˜ä¾¡ï¼‰' in price_df.columns:
                price_df['orig_unit_price'] = pd.to_numeric(price_df['å–å¼•ä¾¡æ ¼ï¼ˆã¡å˜ä¾¡ï¼‰'], errors='coerce')
                # å…ƒã®å˜ä¾¡ãŒã‚ã‚Œã°ä½¿ã„ã€ãªã‘ã‚Œã°è¨ˆç®—å€¤ã§åŸ‹ã‚ã‚‹
                price_df['ã¡å˜ä¾¡'] = price_df['orig_unit_price'].fillna(price_df['calc_unit_price'])
            else:
                # å…ƒã®åˆ—ãŒãªã„å ´åˆã¯è¨ˆç®—å€¤ã‚’æ¡ç”¨
                price_df['ã¡å˜ä¾¡'] = price_df['calc_unit_price']
            
            # --- â˜… ä¿®æ­£ç®‡æ‰€ã“ã“ã¾ã§ ---

            # æœ‰åŠ¹ãªå˜ä¾¡ã¨åœ°åŒºåãŒã‚ã‚‹ãƒ‡ãƒ¼ã‚¿ã®ã¿æ®‹ã™
            price_df = price_df.dropna(subset=['ã¡å˜ä¾¡', 'åœ°åŒºå']).copy()

            if not price_df.empty:
                price_agg = price_df.groupby('åœ°åŒºå')['ã¡å˜ä¾¡'].median().reset_index()
                price_agg = price_agg.rename(columns={'åœ°åŒºå': 'AREA_NAME', 'ã¡å˜ä¾¡': 'Median_Price_sqm'})

                # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆ(merged_dfãŒç©º)ã®è€ƒæ…®
                if merged_df.empty:
                    merged_df = price_agg.set_index('AREA_NAME').fillna(0)
                else:
                    merged_df = merged_df.reset_index().merge(price_agg, on='AREA_NAME', how='left').set_index('AREA_NAME').fillna(0)
                
                merged_df.index.name = "AREA_NAME"
            else:
                if not merged_df.empty: merged_df['Median_Price_sqm'] = 0
        else:
            if not merged_df.empty: merged_df['Median_Price_sqm'] = 0
    else:
        if not merged_df.empty: merged_df['Median_Price_sqm'] = 0

    # ã‚µãƒãƒªãƒ¼ä½œæˆ
    city_summary = merged_df.mean(numeric_only=True).to_dict()

    return merged_df, city_summary


# ==========================================
# 3. Frontend Helper Functions (æ—§ app.py ã®é–¢æ•°)
# ==========================================

def read_csv_flexible(file_or_path, is_path: bool = False) -> pd.DataFrame:
    """ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ï¼šãƒ•ã‚¡ã‚¤ãƒ«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆå¯¾å¿œã®CSVèª­ã¿è¾¼ã¿"""
    encodings = ["cp932", "utf-8-sig", "utf-8"]
    for enc in encodings:
        try:
            if is_path:
                return pd.read_csv(file_or_path, encoding=enc)
            else:
                try:
                    file_or_path.seek(0)
                except Exception:
                    pass
                return pd.read_csv(file_or_path, encoding=enc)
        except Exception:
            continue
    return pd.DataFrame()

def preprocess_price_df(df: pd.DataFrame) -> pd.DataFrame:
    """æ”»ç•¥ã‚¬ã‚¤ãƒ‰è¡¨ç¤ºç”¨ã«å–å¼•ãƒ‡ãƒ¼ã‚¿ã‚’åŠ å·¥"""
    if df is None or df.empty:
        return pd.DataFrame()

    d = df.copy()

    # ã¡å˜ä¾¡ï¼ˆæ•°å€¤åŒ–ï¼‰
    if "å–å¼•ä¾¡æ ¼ï¼ˆã¡å˜ä¾¡ï¼‰" in d.columns:
        d["ã¡å˜ä¾¡"] = pd.to_numeric(d["å–å¼•ä¾¡æ ¼ï¼ˆã¡å˜ä¾¡ï¼‰"], errors="coerce")
    else:
        d["ã¡å˜ä¾¡"] = None

    # ç·é¡ï¼ˆä¸‡å††ï¼‰
    if "å–å¼•ä¾¡æ ¼ï¼ˆç·é¡ï¼‰" in d.columns:
        d["price_man"] = pd.to_numeric(d["å–å¼•ä¾¡æ ¼ï¼ˆç·é¡ï¼‰"], errors="coerce") / 10000
    else:
        d["price_man"] = None

    # é¢ç©ï¼ˆã¡ï¼‰
    def clean_area(x):
        try:
            s = str(x).replace(",", "").replace("ã¡ä»¥ä¸Š", "").replace("m^2", "").replace("m2", "")
            nums = re.findall(r"[\d.]+", s)
            return float(nums[0]) if nums else None
        except Exception:
            return None

    if "é¢ç©ï¼ˆã¡ï¼‰" in d.columns:
        d["area_m2"] = d["é¢ç©ï¼ˆã¡ï¼‰"].apply(clean_area)
    else:
        d["area_m2"] = None

    # åªå˜ä¾¡ï¼ˆä¸‡å††/åªï¼‰
    if "å–å¼•ä¾¡æ ¼ï¼ˆç·é¡ï¼‰" in d.columns and "area_m2" in d.columns:
        total = pd.to_numeric(d["å–å¼•ä¾¡æ ¼ï¼ˆç·é¡ï¼‰"], errors="coerce")
        tsubo = d["area_m2"] / 3.30578
        d["tsubo_price"] = (total / tsubo) / 10000
        d["tsubo_price"] = d["tsubo_price"].round(1)
    else:
        d["tsubo_price"] = None

    # å–å¼•æ™‚æœŸ
    if "å–å¼•æ™‚æœŸ" in d.columns:
        d["period"] = d["å–å¼•æ™‚æœŸ"].astype(str).str.replace("å¹´ç¬¬", "-Q", regex=False).str.replace("å››åŠæœŸ", "", regex=False)
    else:
        d["period"] = None

    # é§…å¾’æ­©
    def clean_minutes(x):
        try:
            nums = re.findall(r"\d+", str(x))
            return int(nums[0]) if nums else None
        except Exception:
            return None

    if "æœ€å¯„é§…ï¼šè·é›¢ï¼ˆåˆ†ï¼‰" in d.columns:
        d["minutes"] = d["æœ€å¯„é§…ï¼šè·é›¢ï¼ˆåˆ†ï¼‰"].apply(clean_minutes)
    else:
        d["minutes"] = None

    # ç¯‰å¹´æ•°
    current_year = datetime.datetime.now().year
    def get_age(x):
        m = re.search(r"(\d{4})", str(x))
        if m:
            return max(0, current_year - int(m.group(1)))
        return None

    if "å»ºç¯‰å¹´" in d.columns:
        d["age"] = d["å»ºç¯‰å¹´"].apply(get_age)
    else:
        d["age"] = None

    return d


# ==========================================
# 4. UI Logic (Streamlit Main App)
# ==========================================

# --- ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šåˆ†æè¨­å®š ---
st.sidebar.title("ğŸ› ï¸ åˆ†æè¨­å®š")

available_cities = get_available_cities()
if not available_cities:
    # çµ±è¨ˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã§ã‚‚åœ°ä¾¡ãƒ‡ãƒ¼ã‚¿ã ã‘ã§å‹•ãã‚ˆã†ã«ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’è¨­å®š
    available_cities = ["å·è¶Šå¸‚"]
    default_cities = ["å·è¶Šå¸‚"]
else:
    default_cities = [available_cities[34]]

target_cities = st.sidebar.multiselect(
    "åˆ†æã™ã‚‹å¸‚åŒºç”ºæ‘ã‚’é¸æŠ",
    options=available_cities,
    default=default_cities,
    help="è¤‡æ•°ã®å¸‚ã‚’é¸ã¶ã¨ã€ãã‚Œã‚‰å…¨ã¦ã®ã‚¨ãƒªã‚¢ã‚’æ¨ªæ–­ã—ã¦åˆ†æãƒ»æ¯”è¼ƒã§ãã¾ã™ã€‚"
)

uploaded_file = st.sidebar.file_uploader(
    "åœ°ä¾¡ãƒ‡ãƒ¼ã‚¿ (CSV) ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["csv"],
    help="å›½åœŸäº¤é€šçœã®ä¸å‹•ç”£å–å¼•ä¾¡æ ¼æƒ…å ±ãªã©ã€‚æœªã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã®å ´åˆã¯ test.csv ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚"
)

uploaded_price_df = None
if uploaded_file is not None:
    uploaded_price_df = read_csv_flexible(uploaded_file, is_path=False)
    if uploaded_price_df.empty:
        st.sidebar.error("èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸï¼ˆæ–‡å­—ã‚³ãƒ¼ãƒ‰/CSVå½¢å¼ã‚’ç¢ºèªï¼‰")
    else:
        st.sidebar.success(f"âœ… {uploaded_file.name} ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        st.sidebar.caption(f"è¡Œæ•°: {len(uploaded_price_df):,}")
else:
    default_test_path = str(BASE_DIR / "test.csv")
    uploaded_price_df = read_csv_flexible(default_test_path, is_path=True)
    if uploaded_price_df.empty:
        st.sidebar.warning("ğŸ“„ test.csv ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸï¼ˆå­˜åœ¨ãƒã‚§ãƒƒã‚¯ï¼‰")
        st.sidebar.caption(f"path: {default_test_path}")
    else:
        st.sidebar.info("ğŸ“„ test.csv ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰")
        st.sidebar.caption(f"è¡Œæ•°: {len(uploaded_price_df):,}")

price_df_pre = preprocess_price_df(uploaded_price_df)

# --- ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰ (ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä½¿ç”¨) ---
@st.cache_data
def load_data(cities, price_df):
    # citiesãŒç©ºã§ã‚‚price_dfãŒã‚ã‚Œã°å‹•ãã‚ˆã†ã«ç·©å’Œ
    if not cities and price_df.empty:
        return pd.DataFrame(), {}
    return get_city_data(target_city_names=cities, uploaded_price_df=price_df)

if not target_cities and uploaded_price_df.empty:
    st.warning("å·¦ã®ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰ã€åˆ†æã—ãŸã„å¸‚åŒºç”ºæ‘ã‚’é¸ã‚“ã§ãã ã•ã„ã€‚")
    st.stop()

df_city, city_summary = load_data(target_cities, uploaded_price_df)

if df_city.empty:
    st.error("é¸æŠã•ã‚ŒãŸã‚¨ãƒªã‚¢ã®ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    st.stop()

area_list = df_city.index.tolist()
numeric_cols = df_city.select_dtypes(include=["float", "int"]).columns.tolist()

# =========================
# ãƒ¡ã‚¤ãƒ³ç”»é¢
# =========================
cities_str = "ãƒ»".join(target_cities)
st.title(f"ğŸ—ºï¸ {cities_str} ã‚¨ãƒªã‚¢æ”»ç•¥ï¼†åˆ†æ")

tab_guide, tab_compare, tab_group = st.tabs(["ğŸ”° æ”»ç•¥ã‚¬ã‚¤ãƒ‰", "ğŸ” å€‹åˆ¥ã‚¨ãƒªã‚¢æ¯”è¼ƒ", "ğŸ†š ã‚°ãƒ«ãƒ¼ãƒ—å¯¾æŠ—"])

# ==========================================
# TAB 1: ğŸ”° æ”»ç•¥ã‚¬ã‚¤ãƒ‰
# ==========================================
with tab_guide:
    st.header("ã‚¨ãƒªã‚¢æ”»ç•¥ã‚¬ã‚¤ãƒ‰ï¼ˆã±ã£ã¨è¦‹ï¼‹å¸‚å ´ãƒ‡ãƒ¼ã‚¿ï¼‰")

    default_area = "æ–°å¯Œç”º"
    default_index = area_list.index(default_area) if default_area in area_list else 0

    selected_area = st.selectbox(
        "æ‹…å½“ã‚¨ãƒªã‚¢ã‚’é¸æŠ",
        area_list,
        index=default_index,
        key="guide_area"
    )

    row = df_city.loc[selected_area]

    # ---- â‘  ã‚¹ãƒˆãƒƒã‚¯ï¼ˆçµ±è¨ˆï¼‰ä¸»è¦KPI ----
    st.subheader("ğŸ“Œ ä¸»è¦æŒ‡æ¨™ã‚µãƒãƒªãƒ¼ï¼ˆçµ±è¨ˆï¼‰")
    c1, c2, c3, c4, c5 = st.columns(5)
    c1.metric("ç·äººå£", f"{row.get('ç·äººå£', 0):,.0f}")
    c2.metric("ä¸–å¸¯æ•°", f"{row.get('ä¸–å¸¯ç·æ•°', 0):,.0f}")
    c3.metric("åœ°ä¾¡ä¸­å¤®å€¤(ã¡)", f"Â¥ {row.get('Median_Price_sqm', 0):,.0f}")
    c4.metric("é«˜é½¢åŒ–ç‡", f"{row.get('é«˜é½¢åŒ–ç‡', 0):.1%}")
    c5.metric("ãƒ•ã‚¡ãƒŸãƒªãƒ¼ç‡", f"{row.get('ãƒ•ã‚¡ãƒŸãƒªãƒ¼ä¸–å¸¯å‰²åˆ', 0):.1%}")

    st.subheader("ğŸ“Š å…¨ä½“å¹³å‡ã¨ã®å·®ï¼ˆçµ±è¨ˆãƒã‚¸ã‚·ãƒ§ãƒ³ï¼‰")
    def metric_vs_avg(label, value, avg, is_percent=True):
        delta = (value or 0) - (avg or 0)
        if is_percent:
            st.metric(label, f"{(value or 0):.1%}", delta=f"{delta:.1%}")
        else:
            st.metric(label, f"{(value or 0):,.0f}", delta=f"{delta:,.0f}")

    d1, d2, d3, d4, d5, d6 = st.columns(6)
    with d1: metric_vs_avg("æŒã¡å®¶ç‡", row.get("æŒã¡å®¶ç‡", 0), city_summary.get("æŒã¡å®¶ç‡", 0), True)
    with d2: metric_vs_avg("å€Ÿå®¶ç‡", row.get("å€Ÿå®¶ç‡", 0), city_summary.get("å€Ÿå®¶ç‡", 0), True)
    with d3: metric_vs_avg("ä¸€æˆ¸å»ºç‡", row.get("ä¸€æˆ¸å»ºç‡", 0), city_summary.get("ä¸€æˆ¸å»ºç‡", 0), True)
    with d4: metric_vs_avg("å…±åŒä½å®…ç‡", row.get("å…±åŒä½å®…ç‡", 0), city_summary.get("å…±åŒä½å®…ç‡", 0), True)
    with d5: metric_vs_avg("å˜èº«ãƒ»å°‘äººæ•°", row.get("å˜èº«ãƒ»å°‘äººæ•°ä¸–å¸¯å‰²åˆ", 0), city_summary.get("å˜èº«ãƒ»å°‘äººæ•°ä¸–å¸¯å‰²åˆ", 0), True)
    with d6: metric_vs_avg("ãƒ•ã‚¡ãƒŸãƒªãƒ¼", row.get("ãƒ•ã‚¡ãƒŸãƒªãƒ¼ä¸–å¸¯å‰²åˆ", 0), city_summary.get("ãƒ•ã‚¡ãƒŸãƒªãƒ¼ä¸–å¸¯å‰²åˆ", 0), True)

    st.markdown("##### ğŸ“Š ãƒã‚¸ã‚·ãƒ§ãƒ³å·®åˆ†ï¼ˆå¹³å‡ã¨ã®å·®ï¼š%ãƒã‚¤ãƒ³ãƒˆï¼‰")
    pos_items = [
        ("æŒã¡å®¶ç‡", "æŒã¡å®¶ç‡"),
        ("å€Ÿå®¶ç‡", "å€Ÿå®¶ç‡"),
        ("ä¸€æˆ¸å»ºç‡", "ä¸€æˆ¸å»ºç‡"),
        ("å…±åŒä½å®…ç‡", "å…±åŒä½å®…ç‡"),
        ("å˜èº«ãƒ»å°‘äººæ•°ä¸–å¸¯å‰²åˆ", "å˜èº«ãƒ»å°‘äººæ•°"),
        ("ãƒ•ã‚¡ãƒŸãƒªãƒ¼ä¸–å¸¯å‰²åˆ", "ãƒ•ã‚¡ãƒŸãƒªãƒ¼"),
    ]
    rows_ = []
    for key, label in pos_items:
        area_val = float(row.get(key, 0) or 0)
        avg_val = float(city_summary.get(key, 0) or 0)
        rows_.append({
            "æŒ‡æ¨™": label,
            "å¹³å‡ã¨ã®å·®(ãƒã‚¤ãƒ³ãƒˆ)": (area_val - avg_val) * 100,
        })
    pos_df = pd.DataFrame(rows_)
    fig_pos = px.bar(pos_df, x="æŒ‡æ¨™", y="å¹³å‡ã¨ã®å·®(ãƒã‚¤ãƒ³ãƒˆ)", text="å¹³å‡ã¨ã®å·®(ãƒã‚¤ãƒ³ãƒˆ)", title="å¸‚å¹³å‡ã¨ã®å·®ï¼ˆï¼‹ãªã‚‰å¹³å‡ã‚ˆã‚Šé«˜ã„ï¼‰")
    fig_pos.update_traces(texttemplate="%{text:.1f}pt")
    st.plotly_chart(fig_pos, use_container_width=True)

    st.divider()

    # ---- â˜… ä½æ°‘ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼ˆå¸‚å ´ã‚µãƒãƒªãƒ¼ã®ä¸Šã«è¿½åŠ ï¼‰ ----
    st.subheader("ğŸ‘¥ ä½æ°‘ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ï¼ˆã©ã‚“ãªäººãŒä½ã‚“ã§ã‚‹ï¼Ÿï¼‰")
    p1, p2, p3, p4 = st.columns(4)
    p1.metric("å­ã©ã‚‚ç‡", f"{row.get('å­ã©ã‚‚ç‡', 0):.1%}")
    p2.metric("ç¾å½¹ç‡", f"{row.get('ç¾å½¹ç‡', 0):.1%}")
    p3.metric("é«˜é½¢è€…ç‡", f"{row.get('é«˜é½¢è€…ç‡', 0):.1%}")
    p4.metric("1ä¸–å¸¯ã‚ãŸã‚Šäººå“¡", f"{row.get('1ä¸–å¸¯å½“ãŸã‚Šäººå“¡', 0):.2f}")

    prof_df = pd.DataFrame({
        "åŒºåˆ†": ["å­ã©ã‚‚", "ç¾å½¹", "é«˜é½¢è€…"],
        "å‰²åˆ": [
            float(row.get("å­ã©ã‚‚ç‡", 0) or 0),
            float(row.get("ç¾å½¹ç‡", 0) or 0),
            float(row.get("é«˜é½¢è€…ç‡", 0) or 0),
        ]
    })
    fig_prof = px.bar(prof_df, x="åŒºåˆ†", y="å‰²åˆ", text="å‰²åˆ", title="å¹´é½¢æ§‹æˆï¼ˆæ¨å®šï¼‰")
    fig_prof.update_traces(texttemplate="%{y:.1%}")
    st.plotly_chart(fig_prof, use_container_width=True)

    st.divider()

    # ---- â‘¡ ãƒ•ãƒ­ãƒ¼ï¼ˆå¸‚å ´/å–å¼•ï¼‰ ----
    st.subheader("ğŸ’° å¸‚å ´ã‚µãƒãƒªãƒ¼ï¼ˆå–å¼•ãƒ‡ãƒ¼ã‚¿ï¼‰")

    market = price_df_pre.copy()

    if not market.empty and "å¸‚åŒºç”ºæ‘å" in market.columns:
        market = market[market["å¸‚åŒºç”ºæ‘å"].isin(target_cities)].copy()

    if not market.empty and "åœ°åŒºå" in market.columns:
        market_area = market[market["åœ°åŒºå"] == selected_area].copy()
    else:
        market_area = pd.DataFrame()

    if market_area.empty:
        st.info("ã“ã®æ‹…å½“ã‚¨ãƒªã‚¢ã«ä¸€è‡´ã™ã‚‹å–å¼•ãƒ‡ãƒ¼ã‚¿ï¼ˆåœ°åŒºåï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        m1, m2, m3, m4 = st.columns(4)

        if "price_man" in market_area.columns and market_area["price_man"].notna().any():
            m1.metric("å¹³å‡å–å¼•ä¾¡æ ¼", f"{market_area['price_man'].mean():,.0f} ä¸‡å††")
        else:
            m1.metric("å¹³å‡å–å¼•ä¾¡æ ¼", "â€”")

        if "tsubo_price" in market_area.columns and market_area["tsubo_price"].notna().any():
            m2.metric("å¹³å‡åªå˜ä¾¡", f"{market_area['tsubo_price'].mean():,.1f} ä¸‡å††/åª")
        else:
            m2.metric("å¹³å‡åªå˜ä¾¡", "â€”")

        if "age" in market_area.columns and market_area["age"].notna().any():
            m3.metric("å¹³å‡ç¯‰å¹´æ•°", f"{market_area['age'].mean():.1f} å¹´")
        else:
            m3.metric("å¹³å‡ç¯‰å¹´æ•°", "â€”")

        m4.metric("ãƒ‡ãƒ¼ã‚¿ä»¶æ•°", f"{len(market_area):,} ä»¶")

        st.subheader("ğŸ“ˆ ç›¸å ´ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæ™‚ç³»åˆ—ï¼‰")
        if "period" in market_area.columns and "tsubo_price" in market_area.columns and market_area["tsubo_price"].notna().any():
            trend = market_area.groupby("period")["tsubo_price"].mean().reset_index()
            fig_tr = px.line(trend, x="period", y="tsubo_price", markers=True, title="æ™‚æœŸã”ã¨ã®å¹³å‡åªå˜ä¾¡æ¨ç§»")
            st.plotly_chart(fig_tr, use_container_width=True)
        else:
            st.warning("æ™‚ç³»åˆ—è¡¨ç¤ºã«å¿…è¦ãªåˆ—ï¼ˆå–å¼•æ™‚æœŸ/åªå˜ä¾¡ï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")

        st.subheader("ğŸ“Š ä¾¡æ ¼å¸¯ã®ãƒœãƒªãƒ¥ãƒ¼ãƒ ã‚¾ãƒ¼ãƒ³")
        if "price_man" in market_area.columns and market_area["price_man"].notna().any():
            fig_hist = px.histogram(market_area, x="price_man", nbins=20, title="ä¾¡æ ¼å¸¯ã”ã¨ã®å–å¼•ä»¶æ•°")
            st.plotly_chart(fig_hist, use_container_width=True)
        else:
            st.warning("ä¾¡æ ¼å¸¯åˆ†å¸ƒã«å¿…è¦ãªåˆ—ï¼ˆå–å¼•ä¾¡æ ¼ï¼ˆç·é¡ï¼‰ï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")

        st.subheader("ğŸ—ï¸ å»ºç‰©æ§‹é€ ï¼ˆã‚·ã‚§ã‚¢ï¼†ä¾¡æ ¼ãƒ¬ãƒ³ã‚¸ï¼‰")
        if "å»ºç‰©ã®æ§‹é€ " in market_area.columns and market_area["å»ºç‰©ã®æ§‹é€ "].notna().any() and "tsubo_price" in market_area.columns:
            struct_df = market_area.dropna(subset=["å»ºç‰©ã®æ§‹é€ "]).copy()
            s1, s2 = st.columns(2)
            with s1:
                fig_pie = px.pie(struct_df, names="å»ºç‰©ã®æ§‹é€ ", title="æ§‹é€ å‰²åˆï¼ˆå¸‚å ´ã‚·ã‚§ã‚¢ï¼‰")
                st.plotly_chart(fig_pie, use_container_width=True)
            with s2:
                fig_box = px.box(
                    struct_df,
                    x="å»ºç‰©ã®æ§‹é€ ",
                    y="tsubo_price",
                    color="å»ºç‰©ã®æ§‹é€ ",
                    title="æ§‹é€ åˆ¥ åªå˜ä¾¡ãƒ¬ãƒ³ã‚¸ï¼ˆç®±ã²ã’ï¼‰",
                    labels={"tsubo_price": "åªå˜ä¾¡(ä¸‡å††/åª)"}
                )
                st.plotly_chart(fig_box, use_container_width=True)

            st.markdown("#### â³ æ§‹é€ Ã—ç¯‰å¹´æ•°ï¼ˆçµŒå¹´ã§ã©ã‚Œãã‚‰ã„è½ã¡ã‚‹ï¼Ÿï¼‰")
            if "age" in struct_df.columns and struct_df["age"].notna().any():
                fig_sc = px.scatter(
                    struct_df,
                    x="age",
                    y="tsubo_price",
                    color="å»ºç‰©ã®æ§‹é€ ",
                    size="area_m2" if "area_m2" in struct_df.columns else None,
                    hover_data=[c for c in ["æœ€å¯„é§…ï¼šåç§°", "minutes"] if c in struct_df.columns],
                    title="ç¯‰å¹´æ•°ã¨åªå˜ä¾¡ï¼ˆæ§‹é€ åˆ¥ï¼‰",
                    labels={"age": "ç¯‰å¹´æ•°(å¹´)", "tsubo_price": "åªå˜ä¾¡(ä¸‡å††/åª)"}
                )
                st.plotly_chart(fig_sc, use_container_width=True)
        else:
            st.warning("æ§‹é€ åˆ†æã«å¿…è¦ãªåˆ—ï¼ˆå»ºç‰©ã®æ§‹é€ /åªå˜ä¾¡ï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")

        st.subheader("ğŸŸ¥ æ¡ä»¶åˆ¥ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆé§…å¾’æ­© Ã— ç¯‰å¹´æ•°ï¼‰")
        if (
            "minutes" in market_area.columns and "age" in market_area.columns and "tsubo_price" in market_area.columns
            and market_area["minutes"].notna().any() and market_area["age"].notna().any() and market_area["tsubo_price"].notna().any()
        ):
            tmp = market_area.dropna(subset=["minutes", "age", "tsubo_price"]).copy()

            tmp["walk_bin"] = pd.cut(tmp["minutes"], bins=[0, 5, 10, 15, 20, 100],
                                     labels=["ï½5åˆ†", "6ï½10åˆ†", "11ï½15åˆ†", "16ï½20åˆ†", "20åˆ†ï½"])
            tmp["age_bin"] = pd.cut(tmp["age"], bins=[0, 5, 10, 20, 30, 100],
                                    labels=["ç¯‰æµ…(ï½5å¹´)", "ç¯‰10å¹´ä»¥å†…", "ç¯‰20å¹´ä»¥å†…", "ç¯‰30å¹´ä»¥å†…", "ç¯‰å¤(30å¹´ï½)"])

            heat = tmp.groupby(["walk_bin", "age_bin"], observed=True)["tsubo_price"].mean().reset_index()
            mat = heat.pivot(index="walk_bin", columns="age_bin", values="tsubo_price")

            fig_h = px.imshow(mat, text_auto=".1f", aspect="auto", title="æ¡ä»¶åˆ¥ã®å¹³å‡åªå˜ä¾¡ãƒãƒˆãƒªã‚¯ã‚¹")
            st.plotly_chart(fig_h, use_container_width=True)
        else:
            st.warning("ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ã«å¿…è¦ãªåˆ—ï¼ˆæœ€å¯„é§…è·é›¢/å»ºç¯‰å¹´/ä¾¡æ ¼/é¢ç© ç­‰ï¼‰ãŒä¸è¶³ã—ã¦ã„ã¾ã™ã€‚")

    st.divider()

    st.subheader("ğŸ˜ï¸ ä½å®…ãƒ»ä¸–å¸¯æ§‹æˆï¼ˆçµ±è¨ˆãƒ»å‰²åˆç³»ï¼‰")
    chart_cols = [
        "æŒã¡å®¶ç‡",
        "å€Ÿå®¶ç‡",
        "ä¸€æˆ¸å»ºç‡",
        "å…±åŒä½å®…ç‡",
        "å˜èº«ãƒ»å°‘äººæ•°ä¸–å¸¯å‰²åˆ",
        "ãƒ•ã‚¡ãƒŸãƒªãƒ¼ä¸–å¸¯å‰²åˆ",
        "é«˜é½¢åŒ–ç‡",
        "å­ã©ã‚‚ç‡",
        "ç¾å½¹ç‡",
        "é«˜é½¢è€…ç‡",
    ]
    chart_cols = [c for c in chart_cols if c in row.index]

    df_chart = pd.DataFrame({"æŒ‡æ¨™": chart_cols, "å‰²åˆ": [row.get(c, 0) for c in chart_cols]})
    fig = px.bar(df_chart, x="æŒ‡æ¨™", y="å‰²åˆ", text="å‰²åˆ", title="å‰²åˆç³»ã®ä¸€è¦§ï¼ˆçµ±è¨ˆãƒ»ã“ã®ã‚¨ãƒªã‚¢ï¼‰")
    fig.update_traces(texttemplate="%{y:.1%}")
    st.plotly_chart(fig, use_container_width=True)

# ==========================================
# TAB 2: ğŸ” å€‹åˆ¥ã‚¨ãƒªã‚¢æ¯”è¼ƒ
# ==========================================
with tab_compare:
    st.header("ãƒãƒ«ãƒã‚¨ãƒªã‚¢æ¯”è¼ƒ")

    comps = st.multiselect(
        "æ¯”è¼ƒã‚¨ãƒªã‚¢",
        area_list,
        default=area_list[:2] if len(area_list) >= 2 else area_list,
        key="comp_multi",
    )

    if comps:
        display_cols = [
            "ç·äººå£",
            "ä¸–å¸¯ç·æ•°",
            "Median_Price_sqm",
            "æŒã¡å®¶ç‡",
            "å€Ÿå®¶ç‡",
            "ä¸€æˆ¸å»ºç‡",
            "å…±åŒä½å®…ç‡",
            "é«˜é½¢åŒ–ç‡",
            "å˜èº«ãƒ»å°‘äººæ•°ä¸–å¸¯å‰²åˆ",
            "ãƒ•ã‚¡ãƒŸãƒªãƒ¼ä¸–å¸¯å‰²åˆ",
            "å­ã©ã‚‚ç‡",
            "ç¾å½¹ç‡",
            "é«˜é½¢è€…ç‡",
        ]
        display_cols = [c for c in display_cols if c in df_city.columns]

        st.markdown("##### ğŸ“‹ æ•°å€¤æ¯”è¼ƒ")
        st.dataframe(df_city.loc[comps, display_cols].T.style.format("{:,.4f}"), use_container_width=True)

        st.markdown("##### ğŸ“Š ã‚°ãƒ©ãƒ•æ¯”è¼ƒ")
        cm = st.selectbox("ã‚°ãƒ©ãƒ•æŒ‡æ¨™", numeric_cols, key="comp_metric")

        df_tmp = df_city.loc[comps].reset_index()  # indexåã¯ "AREA_NAME" ã«è¨­å®šæ¸ˆã¿
        fig_comp = px.bar(df_tmp, x="AREA_NAME", y=cm, text=cm, title=f"{cm} ã®æ¯”è¼ƒ", color="AREA_NAME")

        if "ç‡" in cm or "å‰²åˆ" in cm:
            fig_comp.update_traces(texttemplate="%{y:.1%}")
        elif cm == "Median_Price_sqm":
            fig_comp.update_traces(texttemplate="Â¥ %{y:,.0f}")
        else:
            fig_comp.update_traces(texttemplate="%{y:,.0f}")

        st.plotly_chart(fig_comp, use_container_width=True)

# ==========================================
# TAB 3: ğŸ†š ã‚°ãƒ«ãƒ¼ãƒ—å¯¾æŠ—
# ==========================================
with tab_group:
    st.header("ã‚°ãƒ«ãƒ¼ãƒ—å¯¾æŠ—åˆ†æ")

    col_g1, col_g2 = st.columns(2)
    with col_g1:
        group_a = st.multiselect("ğŸ”´ ãƒãƒ¼ãƒ A", area_list, key="ga")
    with col_g2:
        group_b = st.multiselect("ğŸ”µ ãƒãƒ¼ãƒ B", area_list, key="gb")

    if group_a and group_b:
        st.divider()

        def agg_grp(df, areas, label):
            sub = df.loc[areas]
            agg = {}

            for c in ["ç·äººå£", "ä¸–å¸¯ç·æ•°", "æŒã¡å®¶", "æ°‘å–¶å€Ÿå®¶", "ä¸€æˆ¸å»º", "å…±åŒä½å®…"]:
                if c in df.columns:
                    agg[c] = sub[c].sum()

            w_col = "ä¸–å¸¯ç·æ•°" if "ä¸–å¸¯ç·æ•°" in df.columns else None
            for c in [col for col in df.columns if ("ç‡" in col or "å‰²åˆ" in col)]:
                if w_col and sub[w_col].sum() > 0:
                    agg[c] = (sub[c] * sub[w_col]).sum() / sub[w_col].sum()
                else:
                    agg[c] = sub[c].mean()

            if "Median_Price_sqm" in df.columns:
                agg["Median_Price_sqm"] = sub["Median_Price_sqm"].mean()

            agg["Team"] = label
            return agg

        res_a = agg_grp(df_city, group_a, "ãƒãƒ¼ãƒ A")
        res_b = agg_grp(df_city, group_b, "ãƒãƒ¼ãƒ B")

        st.subheader("âš”ï¸ å¯¾æ±ºçµæœ")
        c1, c2, c3, c4 = st.columns(4)

        v_a, v_b = res_a.get("ç·äººå£", 0), res_b.get("ç·äººå£", 0)
        c1.metric("ç·äººå£", f"{v_a:,.0f}", delta=f"{v_a - v_b:,.0f}")

        v_a, v_b = res_a.get("Median_Price_sqm", 0), res_b.get("Median_Price_sqm", 0)
        c2.metric("å¹³å‡åœ°ä¾¡", f"Â¥ {v_a:,.0f}", delta=f"{v_a - v_b:,.0f}")

        v_a, v_b = res_a.get("æŒã¡å®¶ç‡", 0), res_b.get("æŒã¡å®¶ç‡", 0)
        c3.metric("æŒã¡å®¶ç‡", f"{v_a:.1%}", delta=f"{v_a - v_b:.1%}")

        v_a, v_b = res_a.get("é«˜é½¢åŒ–ç‡", 0), res_b.get("é«˜é½¢åŒ–ç‡", 0)
        c4.metric("é«˜é½¢è€…ä¸–å¸¯ç‡", f"{v_a:.1%}", delta=f"{v_a - v_b:.1%}")

        st.markdown("##### ğŸ“‹ è©³ç´°æ¯”è¼ƒ")
        st.dataframe(pd.DataFrame([res_a, res_b]).set_index("Team").T.style.format("{:,.4f}"), use_container_width=True)

        st.markdown("##### ğŸ“Š ã‚°ãƒ©ãƒ•æ¯”è¼ƒ")
        vm = st.selectbox("æ¯”è¼ƒæŒ‡æ¨™", numeric_cols, key="vs_metric")
        ch_data = pd.DataFrame(
            [{"Team": "ãƒãƒ¼ãƒ A", "Value": res_a.get(vm, 0)}, {"Team": "ãƒãƒ¼ãƒ B", "Value": res_b.get(vm, 0)}]
        )

        fig_vs = px.bar(ch_data, x="Team", y="Value", color="Team", text="Value", title=f"{vm} ã®ãƒãƒ¼ãƒ æ¯”è¼ƒ")
        if "ç‡" in vm or "å‰²åˆ" in vm:
            fig_vs.update_traces(texttemplate="%{y:.1%}")
        elif vm == "Median_Price_sqm":
            fig_vs.update_traces(texttemplate="Â¥ %{y:,.0f}")
        else:
            fig_vs.update_traces(texttemplate="%{y:,.0f}")

        st.plotly_chart(fig_vs, use_container_width=True)